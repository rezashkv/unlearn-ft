model:
  prediction_model:
    pretrained_model_name_or_path: stabilityai/stable-unet-2-1
    input_perturbation: 0.0
    revision: null
    resolution: 512
    use_ema: false
    noise_offset: 0.0
    prediction_type: v_prediction
    max_scheduler_steps: null

    gated_ff: true
    ff_gate_width: 32

data:
  dataset_name: null
  data_files: null
  dataset_config_name: null
  data_dir: "path/to//coco"
  max_train_samples: null
  max_validation_samples: 1000
  year: 2017

  image_column: "image"
  caption_column: "caption"
  prompts: null
  max_generated_samples: 2
  dataloader:
    dataloader_num_workers: 0
    train_batch_size: 128
    validation_batch_size: 32
    image_generation_batch_size: 1
    center_crop: false
    random_flip: true

training:
  pruning_target: 0.7
  pruning_method: "magnitude"

  num_train_epochs: null
  max_train_steps: 30000
  validation_steps: 10000
  image_logging_steps: 10000
  checkpoint_steps: 5000
  num_inference_steps: 10 # number of scheduler steps to run for image generation

  mixed_precision: null
  gradient_accumulation_steps: 1
  gradient_checkpointing: false
  local_rank: -1
  allow_tf32: false
  enable_xformers_memory_efficient_attention: false

  losses:
    diffusion_loss:
      snr_gamma: 5.0
      weight: 1.0

    distillation_loss:
      weight: 2.0

    block_loss:
      weight: 0.0


  optim:
    prediction_model_learning_rate: 5e-6
    prediction_model_weight_decay: 0.00

    optimizer: "adamw"
    use_8bit_adam: false
    adam_beta1: 0.9
    adam_beta2: 0.999
    adam_epsilon: 1e-08

    scale_lr: false
    lr_scheduler: "constant_with_warmup" # see pdm.utils.arg_utils for available options
    lr_warmup_steps: 250


  hf_hub:
    push_to_hub: false
    hub_token: null
    hub_model_id: null

  logging:
    logging_dir: "path/to/logs/"

    report_to: "wandb"
    tracker_project_name: "diffusion-pruning"
    wandb_log_dir: "path/to/wandb"

    checkpoints_total_limit: null
    auto_checkpoint_step: false
    resume_from_checkpoint: latest # or null

